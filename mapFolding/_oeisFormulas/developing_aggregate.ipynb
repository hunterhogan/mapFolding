{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c87828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path  # NOTE For testing\n",
    "import numpy\n",
    "import pickle  # NOTE For testing\n",
    "\n",
    "# NOTE For testing\n",
    "listArrayCurveLocationsAnalyzed: list[numpy.ndarray[tuple[int, int], numpy.dtype[numpy.uint64]]] = pickle.loads(Path(\"listArrayCurveLocationsAnalyzed.pkl\").read_bytes())\n",
    "\"\"\"NOTE data overview\n",
    "index=0\t(194, 2)\t194=Unique curveLocations\n",
    "index=1\t(276, 2)\t276=Unique curveLocations\n",
    "index=2\t(276, 2)\t276=Unique curveLocations\n",
    "index=3\t(207, 2)\t132=Unique curveLocations\n",
    "\n",
    "953 Total rows\n",
    "470 Total unique curveLocations\n",
    "\n",
    "Created by running `A000682(15)` and pickling `listArrayCurveLocationsAnalyzed` at the end of the while loop when `bridges==7`.\n",
    "\"\"\"\n",
    "\n",
    "indexDistinctCrossings: int = 0\n",
    "indexCurveLocations: int = 1\n",
    "\n",
    "\"\"\"NOTE What, why, and how:\n",
    "I'm trying to collect \"coordinates\" and create a low-quality look-up system.\n",
    "\n",
    "Hypothetically, given a value for `curveLocations`, I could create a comprehensive `list` of coordinates of all cells with that\n",
    "value, which would implicitly give me a list of coordinates of all cells with the corresponding `distinctCrossings`. One\n",
    "coordinate value could look like, for example, `listArrayCurveLocationsAnalyzed[1][:, indexCurveLocations][81]`. (I think.) In any\n",
    "event, `listArrayCurveLocationsAnalyzed` is indexed in a predictable way. And each array in the list is indexed in a predictable\n",
    "way. The trick is to combine the two indexing systems into one coordinate value.\n",
    "\n",
    "I have a few goals with this approach.\n",
    "- I believe my clumsy prototype can be improved to be faster and less memory expensive.\n",
    "- I _think_ the memory requirements of a coordinate system are less expensive than moving the actual data.\n",
    "- I _think_ the process of collecting coordinates is faster than moving data.\n",
    "- I want to create `arrayAggregated` from `listArrayCurveLocationsAnalyzed` by moving/computing the data with EXACTLY ONE\n",
    "vectorized operation. I _feel_ that is possible if I can structure the coordinate information in a clever way.\n",
    "\"\"\"\n",
    "\n",
    "# NOTE Purpose and effect: Create a list of coordinates as a tuple\n",
    "listOfCoordinates: list[tuple[numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.intp]], numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.uint64]], int]] = []\n",
    "for index, arrayCurveLocationsAnalyzed in enumerate(listArrayCurveLocationsAnalyzed):\n",
    "\t# NOTE Development: I am using `index` at the moment. I hope that vectorizing will obsolete it.\n",
    "\tarrayCurveLocationsUniqueHere , indicesDistinctCurvesToSum = numpy.unique(arrayCurveLocationsAnalyzed[:, indexCurveLocations], return_inverse=True)\n",
    "\t# NOTE Development: the tuple must be indexed, so to make it easier on myself, mirror the array indexing.\n",
    "\tlistOfCoordinates.append((indicesDistinctCurvesToSum, arrayCurveLocationsUniqueHere, index))\n",
    "\n",
    "# NOTE Purpose and effect: This is the correct shape for `arrayAggregated`, and each column has a unique `curveLocations` value.\n",
    "arrayAggregated: numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.uint64]] = numpy.tile(\n",
    "\tA=reduce(numpy.union1d, [Z0Z_tuple[1] for Z0Z_tuple in listOfCoordinates])\n",
    "\t, reps=(2, 1)\n",
    ").T\n",
    "\n",
    "# NOTE Purpose and effect: Literally zero-out the values for `distinctCrossings`.\n",
    "arrayAggregated[:, indexDistinctCrossings] = 0\n",
    "\n",
    "# NOTE Purpose and effect: for each `curveLocations` in `arrayAggregated`, sum the `distinctCrossings` across all `arrayCurveLocationsAnalyzed`.\n",
    "for TESTindexOfOneRow in range(len(arrayAggregated[:, indexCurveLocations])):\n",
    "\tTESTcurveLocationsUnique = arrayAggregated[TESTindexOfOneRow, indexCurveLocations]\n",
    "\n",
    "\tfor index in range(len(listOfCoordinates)):\n",
    "\t\tif TESTcurveLocationsUnique in listOfCoordinates[index][indexCurveLocations]:\n",
    "\t\t\tTESTindexArrayCurveLocationsUniqueHere: int = listOfCoordinates[index][indexCurveLocations].tolist().index(TESTcurveLocationsUnique)\n",
    "\t\t\tselectTESTindexArrayCurveLocationsUniqueHere: numpy.ndarray[tuple[int], numpy.dtype[numpy.bool_]] = listOfCoordinates[index][indexDistinctCrossings] == TESTindexArrayCurveLocationsUniqueHere\n",
    "\t\t\tTESTarrayDistinctCrossingsOfTESTcurveLocationsUnique: numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.uint64]] = numpy.atleast_1d(listArrayCurveLocationsAnalyzed[index][selectTESTindexArrayCurveLocationsUniqueHere, indexDistinctCrossings])\n",
    "\t\t\t# NOTE Development: A little voice in my head is telling me `numpy.add.reduce`.\n",
    "\t\t\tTESTsumDistinctCrossings: numpy.uint64 = numpy.sum(TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique)\n",
    "\t\t\tarrayAggregated[TESTindexOfOneRow, indexDistinctCrossings] += TESTsumDistinctCrossings\n",
    "\n",
    "\n",
    "# # NOTE Proof of concept, sum the same `curveLocations` across all arrays START-----------------------------------------------------------------------\n",
    "# print(TESTindexOfOneRow := 2)\n",
    "# print(arrayAggregated[0:10, indexCurveLocations])\n",
    "# print(arrayAggregated[TESTindexOfOneRow, indexCurveLocations])\n",
    "# TESTcurveLocationsUnique = arrayAggregated[TESTindexOfOneRow, indexCurveLocations]\n",
    "\n",
    "# for index in range(len(listOfCoordinates)):\n",
    "# \tprint(f\"{index = }\")\n",
    "# \tprint(listOfCoordinates[index][indexCurveLocations][0:10])\n",
    "# \tif TESTcurveLocationsUnique in listOfCoordinates[index][indexCurveLocations]:\n",
    "# \t\tTESTindexArrayCurveLocationsUniqueHere: int = listOfCoordinates[index][indexCurveLocations].tolist().index(TESTcurveLocationsUnique)\n",
    "# \t\tprint(f\"{TESTindexArrayCurveLocationsUniqueHere=}\")\n",
    "# \t\tprint(listOfCoordinates[index][indexDistinctCrossings][0:10])\n",
    "# \t\tselectTESTindexArrayCurveLocationsUniqueHere: numpy.ndarray[tuple[int], numpy.dtype[numpy.bool_]] = listOfCoordinates[index][indexDistinctCrossings] == TESTindexArrayCurveLocationsUniqueHere\n",
    "# \t\tprint(selectTESTindexArrayCurveLocationsUniqueHere[0:10])\n",
    "# \t\tprint(listArrayCurveLocationsAnalyzed[index][0:10, indexDistinctCrossings])\n",
    "# \t\tTESTarrayDistinctCrossingsOfTESTcurveLocationsUnique: numpy.ndarray[tuple[int, ...], numpy.dtype[numpy.uint64]] = numpy.atleast_1d(listArrayCurveLocationsAnalyzed[index][selectTESTindexArrayCurveLocationsUniqueHere, indexDistinctCrossings])\n",
    "# \t\tprint(f\"{TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique=}\")\n",
    "# \t\t# NOTE Development: A little voice in my head is telling me `numpy.add.reduce`.\n",
    "# \t\tTESTsumDistinctCrossings: numpy.uint64 = numpy.sum(TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique)\n",
    "# \t\tprint(f\"{TESTsumDistinctCrossings=}\")\n",
    "# \t\tarrayAggregated[TESTindexOfOneRow, indexDistinctCrossings] += TESTsumDistinctCrossings\n",
    "\n",
    "# print(arrayAggregated[TESTindexOfOneRow])\n",
    "# # NOTE Proof of concept, sum the same `curveLocations` across all arrays END -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc183eb",
   "metadata": {},
   "source": [
    "# Analysis of proof of concept loop for one row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7eee0",
   "metadata": {},
   "source": [
    "```python\n",
    "2\n",
    "[ 22  41  60  63 326 338 364 367 376 379]\n",
    "60 # `curveLocations` value for which we want the sum of `distinctCrossings` across all `arrayCurveLocationsAnalyzed`.\n",
    "\n",
    "index = 0 # i.e., `listArrayCurveLocationsAnalyzed[0]`\n",
    "[  63  367  379  671  695  975  987  999 1011 1023]\n",
    "# `curveLocations` 60 is not in the list above, so we must skip it.\n",
    "\n",
    "index = 1\n",
    "[ 41  60  63 364 367 376 379 382 649 668]\n",
    "TESTindexArrayCurveLocationsUniqueHere=1 # `curveLocations` 60 is at index 1 in the list above.\n",
    "[ 0  1  2  8 11  9 10 12 13 14] # A list of indices\n",
    "[False  True False False False False False False False False] # Selector is True where list-element matches `TESTindexArrayCurveLocationsUniqueHere`\n",
    "[ 66  64 108  64 108  26  14  14  50 154] # Selector is applied to this list\n",
    "TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique=array([64], dtype=uint64)\n",
    "TESTsumDistinctCrossings=np.uint64(64)\n",
    "\n",
    "index = 2\n",
    "[ 22  60  63 326 338 364 367 376 379 382]\n",
    "TESTindexArrayCurveLocationsUniqueHere=1\n",
    "[0 3 4 1 2 5 7 6 8 9]\n",
    "[False False False  True False False False False False False]\n",
    "[ 66  64 108  64 108  26  14  14  50 154]\n",
    "TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique=array([64], dtype=uint64)\n",
    "TESTsumDistinctCrossings=np.uint64(64)\n",
    "\n",
    "index = 3\n",
    "[ 22  41  60  63 326 338 364 367 376 379]\n",
    "TESTindexArrayCurveLocationsUniqueHere=2\n",
    "[0 1 2 2 3 4 5 4 6 6]\n",
    "[False False  True  True False False False False False False]\n",
    "[108 108  14  14  50  14  50  78   2   2]\n",
    "TESTarrayDistinctCrossingsOfTESTcurveLocationsUnique=array([14, 14], dtype=uint64)\n",
    "TESTsumDistinctCrossings=np.uint64(28)\n",
    "[156  60]\n",
    "\n",
    "156 = 64 + 64 + 28\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5eadf",
   "metadata": {},
   "source": [
    "# `_aggregate` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "# pyright: standard\n",
    "import numpy\n",
    "\n",
    "# NOTE `arrayCurveLocationsAnalyzed` and `arrayAggregated`: Always use semantic index identifiers: Never hardcode the indices.\n",
    "indexDistinctCrossings: int = 0\n",
    "indexCurveLocations: int = 1\n",
    "\n",
    "def _aggregate(listArrayCurveLocationsAnalyzed: list[numpy.ndarray[tuple[int, int], numpy.dtype[numpy.uint64]]]):\n",
    "\t\"\"\"Common aggregation tasks.\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
