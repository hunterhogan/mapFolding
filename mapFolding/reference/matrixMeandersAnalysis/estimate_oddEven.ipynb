{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4b2c5f",
   "metadata": {},
   "source": [
    "# Estimating Bucket Counts from (n, k)\n",
    "This notebook continues prior work to derive a closed-form (logarithmic) regression formula estimating the column `buckets` as a function of `n` and `k` using the dataset `df_oddEven.csv`.\n",
    "\n",
    "We follow a continuation-oriented outline to make this reproducible and resumable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539c6cd",
   "metadata": {},
   "source": [
    "## 1. Load Previous Environment State\n",
    "If a prior serialized state file existed we would reload it here. For now, we simulate the pattern and provide hooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b521c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No prior state file present; proceeding fresh.\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Load Previous Environment State (placeholder)\n",
    "from __future__ import annotations\n",
    "import json, os, math, datetime, sys\n",
    "from pathlib import Path\n",
    "path_state = Path('state_estimate_buckets.json')\n",
    "state_loaded = {}\n",
    "if path_state.exists():\n",
    "    try:\n",
    "        state_loaded = json.loads(path_state.read_text())\n",
    "        print('Loaded prior state keys:', list(state_loaded.keys()))\n",
    "    except Exception as exception:\n",
    "        print('Failed to load previous state file:', exception)\n",
    "else:\n",
    "    print('No prior state file present; proceeding fresh.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c35f9",
   "metadata": {},
   "source": [
    "## 2. Re-import Libraries and Configuration\n",
    "We import required standard libraries and numerical tooling. Project uses explicit module names (no abbreviations) per conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7ef177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Numpy version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Imports and configuration\n",
    "import csv\n",
    "import statistics\n",
    "import numpy  # project prefers full name, not abbreviation\n",
    "from math import log, exp\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import pprint\n",
    "\n",
    "numpy.set_printoptions(linewidth=130, suppress=True)\n",
    "print('Python version:', sys.version)\n",
    "print('Numpy version:', numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35d9ca",
   "metadata": {},
   "source": [
    "## 3. Reload Cached / Intermediate Data\n",
    "Load the `df_oddEven.csv` dataset containing (n, k, buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666a3b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38 rows from df_oddEven.csv\n",
      "Preview first 5 rows:\n",
      "{'n': 5, 'k': 3, 'buckets': 7}\n",
      "{'n': 7, 'k': 3, 'buckets': 23}\n",
      "{'n': 9, 'k': 5, 'buckets': 42}\n",
      "{'n': 11, 'k': 5, 'buckets': 138}\n",
      "{'n': 13, 'k': 7, 'buckets': 207}\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Load data\n",
    "path_dataset = Path('df_oddEven.csv')\n",
    "rows = []\n",
    "with path_dataset.open() as handle:\n",
    "    reader = csv.DictReader(handle)\n",
    "    for row in reader:\n",
    "        rows.append({key: int(value) for key, value in row.items()})\n",
    "print(f'Loaded {len(rows)} rows from {path_dataset}')\n",
    "print('Preview first 5 rows:')\n",
    "for preview in rows[:5]:\n",
    "    print(preview)\n",
    "\n",
    "n_values = [r['n'] for r in rows]\n",
    "k_values = [r['k'] for r in rows]\n",
    "bucket_values = [r['buckets'] for r in rows]\n",
    "assert len(n_values) == len(k_values) == len(bucket_values) > 0, 'Dataset length mismatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba2662",
   "metadata": {},
   "source": [
    "## 4. Resume Parameter Definitions\n",
    "Define constants and feature selection choices for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fcaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature switches: True True\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Parameters\n",
    "use_feature_product = True\n",
    "use_feature_ratios = True\n",
    "print('Feature switches:', use_feature_product, use_feature_ratios)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7339133",
   "metadata": {},
   "source": [
    "## 5. Reconstruct Random State for Reproducibility\n",
    "Set seeds (not strictly required for deterministic linear algebra, but included for pattern consistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e30fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set to 1729\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Random state\n",
    "import random\n",
    "random_seed = 1729  # Hardy-Ramanujan number for fun\n",
    "random.seed(random_seed)\n",
    "numpy.random.seed(random_seed)\n",
    "print('Seeds set to', random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ea65f",
   "metadata": {},
   "source": [
    "## 6. Continue Data Processing Pipeline Step\n",
    "Construct logarithmic and ratio-based features and perform least squares fit in log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf38be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "  bias         = -679.088264366881\n",
      "  log_n        = +864.829109159972\n",
      "  log_k        = -873.871846814867\n",
      "  log_n_log_k  = +3.487829177620\n",
      "  k_over_n     = +943.512567960048\n",
      "  n_over_k     = -193.640628682536\n",
      "R^2 (log space): 0.990524\n",
      "MAPE %: 39.08\n",
      "n= 5 k= 3 actual=         7 predicted=         9.9 err%= 41.68\n",
      "n= 7 k= 3 actual=        23 predicted=        41.9 err%= 82.27\n",
      "n= 9 k= 5 actual=        42 predicted=        14.1 err%=-66.38\n",
      "n=11 k= 5 actual=       138 predicted=        95.5 err%=-30.78\n",
      "n=13 k= 7 actual=       207 predicted=        91.3 err%=-55.91\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Feature construction and regression\n",
    "n_array = numpy.array(n_values, dtype=float)\n",
    "k_array = numpy.array(k_values, dtype=float)\n",
    "buckets_array = numpy.array(bucket_values, dtype=float)\n",
    "\n",
    "log_n = numpy.log(n_array)\n",
    "log_k = numpy.log(k_array)\n",
    "product_log = log_n * log_k\n",
    "ratio_k_over_n = k_array / n_array\n",
    "ratio_n_over_k = n_array / k_array\n",
    "\n",
    "# Design matrix (full model chosen earlier)\n",
    "X = numpy.column_stack([\n",
    "    numpy.ones_like(n_array),\n",
    "    log_n,\n",
    "    log_k,\n",
    "    product_log,\n",
    "    ratio_k_over_n,\n",
    "    ratio_n_over_k,\n",
    "])\n",
    "log_buckets = numpy.log(buckets_array)\n",
    "coefficients, residuals, rank, singular_values = numpy.linalg.lstsq(X, log_buckets, rcond=None)\n",
    "coefficients_named = {\n",
    "    'bias': float(coefficients[0]),\n",
    "    'log_n': float(coefficients[1]),\n",
    "    'log_k': float(coefficients[2]),\n",
    "    'log_n_log_k': float(coefficients[3]),\n",
    "    'k_over_n': float(coefficients[4]),\n",
    "    'n_over_k': float(coefficients[5]),\n",
    "}\n",
    "print('Coefficients:')\n",
    "for key, value in coefficients_named.items():\n",
    "    print(f'  {key:12s} = {value:+.12f}')\n",
    "\n",
    "log_buckets_pred = X @ coefficients\n",
    "buckets_pred = numpy.exp(log_buckets_pred)\n",
    "ss_res = numpy.sum((log_buckets - log_buckets_pred) ** 2)\n",
    "ss_tot = numpy.sum((log_buckets - log_buckets.mean()) ** 2)\n",
    "coefficient_determination = 1 - ss_res / ss_tot\n",
    "mean_absolute_percentage_error = float(numpy.mean(numpy.abs((buckets_pred - buckets_array) / buckets_array)) * 100)\n",
    "print(f'R^2 (log space): {coefficient_determination:.6f}')\n",
    "print(f'MAPE %: {mean_absolute_percentage_error:.2f}')\n",
    "\n",
    "# Final pure-Python estimation function (math only) ----------------------------------\n",
    "from math import log as math_log, exp as math_exp\n",
    "\n",
    "def estimateBuckets(n: int, k: int) -> float:\n",
    "    \"\"\"Estimate the number of buckets for given integers n and k.\n",
    "\n",
    "    Model form (log-space):\n",
    "        log(estimate) = a\n",
    "            + b * log(n)\n",
    "            + c * log(k)\n",
    "            + d * log(n)*log(k)\n",
    "            + e * (k / n)\n",
    "            + f * (n / k)\n",
    "\n",
    "    Coefficients were obtained via ordinary least squares fit on log(buckets)\n",
    "    using the dataset in df_oddEven.csv (38 observations). The regression achieved\n",
    "    R^2 ≈ {coefficient_determination:.5f} (log space) with MAPE ≈ {mean_absolute_percentage_error:.2f}% on training data.\n",
    "\n",
    "    NOTE: This is an empirical approximation; extrapolation outside the range\n",
    "    n ∈ [{min(n_values)}, {max(n_values)}], k ∈ [{min(k_values)}, {max(k_values)}] may be unreliable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Primary size parameter (must be > 0)\n",
    "    k : int\n",
    "        Secondary size parameter (must be > 0)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Estimated bucket count (positive real number). Caller may round if an\n",
    "        integer is desired.\n",
    "    \"\"\"\n",
    "    if not isinstance(n, int) or n <= 0:\n",
    "        raise ValueError(f'allegedInt n must be positive int, got {n!r}')\n",
    "    if not isinstance(k, int) or k <= 0:\n",
    "        raise ValueError(f'allegedInt k must be positive int, got {k!r}')\n",
    "\n",
    "    a = -679.088264366881\n",
    "    b =  864.829109159972\n",
    "    c = -873.871846814867\n",
    "    d =    3.487829177620\n",
    "    e =  943.512567960048\n",
    "    f = -193.640628682536\n",
    "\n",
    "    ln_n = math_log(n)\n",
    "    ln_k = math_log(k)\n",
    "    value_log = (a\n",
    "                 + b * ln_n\n",
    "                 + c * ln_k\n",
    "                 + d * ln_n * ln_k\n",
    "                 + e * (k / n)\n",
    "                 + f * (n / k))\n",
    "    return math_exp(value_log)\n",
    "\n",
    "# Quick smoke test for the function on first few rows\n",
    "for sample in rows[:5]:\n",
    "    predicted = estimateBuckets(sample['n'], sample['k'])\n",
    "    print(f\"n={sample['n']:>2} k={sample['k']:>2} actual={sample['buckets']:>10} predicted={predicted:>12.1f} err%={(predicted-sample['buckets'])/sample['buckets']*100:6.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27e6d0",
   "metadata": {},
   "source": [
    "## 7. Append New Analysis Cells\n",
    "Residual diagnostics and error summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293290e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent error summary (in-sample):\n",
      "  min    -66.38\n",
      "  max     98.19\n",
      "  mean    10.47\n",
      "  std     46.65\n",
      "\n",
      "Top 5 absolute percent errors:\n",
      "n=17 k=7 actual=1739 pred=3446.5 err%=98.19\n",
      "n=37 k=19 actual=2052330 pred=3898808.5 err%=89.97\n",
      "n=33 k=17 actual=445014 pred=839731.7 err%=88.70\n",
      "n=7 k=3 actual=23 pred=41.9 err%=82.27\n",
      "n=27 k=11 actual=140580 pred=256036.2 err%=82.13\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Residual analysis\n",
    "residuals_linear = buckets_pred - buckets_array\n",
    "percent_errors = (residuals_linear / buckets_array) * 100\n",
    "print('Percent error summary (in-sample):')\n",
    "print('  min  %8.2f' % percent_errors.min())\n",
    "print('  max  %8.2f' % percent_errors.max())\n",
    "print('  mean %8.2f' % percent_errors.mean())\n",
    "print('  std  %8.2f' % percent_errors.std())\n",
    "# Identify largest 5 absolute percent errors\n",
    "indices_sorted = numpy.argsort(numpy.abs(percent_errors))[::-1][:5]\n",
    "print('\\nTop 5 absolute percent errors:')\n",
    "for index in indices_sorted:\n",
    "    print(f\"n={n_array[index]:.0f} k={k_array[index]:.0f} actual={buckets_array[index]:.0f} pred={buckets_pred[index]:.1f} err%={percent_errors[index]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407548f",
   "metadata": {},
   "source": [
    "## 8. Add Incremental Model Training Block\n",
    "Not applicable (closed-form regression); section retained for structural consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c889842",
   "metadata": {},
   "source": [
    "## 9. Extend Visualization Section\n",
    "Generate comparative textual visualization (no plotting dependency added)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1bb11ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample comparative rows (every ~5th):\n",
      "n= 5 k= 3 actual=         7 pred=         9.9 err%= 41.68\n",
      "n=15 k= 7 actual=       723 pred=       481.8 err%=-33.36\n",
      "n=21 k= 9 actual=     10072 pred=     15944.8 err%= 58.31\n",
      "n=29 k=15 actual=     96475 pred=    165223.8 err%= 71.26\n",
      "n=31 k=13 actual=    825471 pred=   1105433.2 err%= 33.92\n",
      "n=35 k=15 actual=   4550074 pred=   4442952.2 err%= -2.35\n",
      "n=39 k=17 actual=  24006862 pred=  16918036.9 err%=-29.53\n",
      "n=43 k=19 actual= 122844418 pred=  61388593.2 err%=-50.03\n"
     ]
    }
   ],
   "source": [
    "# Section 9: Comparative textual output\n",
    "print('Sample comparative rows (every ~5th):')\n",
    "for index in range(0, len(n_array), 5):\n",
    "    print(f\"n={int(n_array[index]):>2} k={int(k_array[index]):>2} actual={int(buckets_array[index]):>10} pred={buckets_pred[index]:>12.1f} err%={(buckets_pred[index]-buckets_array[index])/buckets_array[index]*100:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a53b4",
   "metadata": {},
   "source": [
    "## 10. Persist Updated Artifacts and Checkpoints\n",
    "Save coefficient dictionary and basic metadata for resuming later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b66464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State file written with keys: ['timestamp', 'coefficients', 'r2_log_space', 'mape_percent', 'n_min', 'n_max', 'k_min', 'k_max']\n"
     ]
    }
   ],
   "source": [
    "# Section 10: Save state\n",
    "state_to_save = {\n",
    "    'timestamp': datetime.datetime.now().isoformat() + 'Z',\n",
    "    'coefficients': coefficients_named,\n",
    "    'r2_log_space': float(coefficient_determination),\n",
    "    'mape_percent': float(mean_absolute_percentage_error),\n",
    "    'n_min': min(n_values),\n",
    "    'n_max': max(n_values),\n",
    "    'k_min': min(k_values),\n",
    "    'k_max': max(k_values),\n",
    "}\n",
    "Path('state_estimate_buckets.json').write_text(json.dumps(state_to_save, indent=2))\n",
    "print('State file written with keys:', list(state_to_save.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ee5d9",
   "metadata": {},
   "source": [
    "## 11. Lightweight Regression Tests for Continuation Integrity\n",
    "Assert schema conformity and acceptable model drift thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6a5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic integrity checks passed.\n"
     ]
    }
   ],
   "source": [
    "# Section 11: Integrity tests\n",
    "assert all(isinstance(v, int) and v > 0 for v in n_values), 'n contains invalid entries'\n",
    "assert all(isinstance(v, int) and v > 0 for v in k_values), 'k contains invalid entries'\n",
    "assert 0.9 < coefficient_determination < 1.01, 'R^2 out of plausible expected bounds'\n",
    "# Allow higher MAPE given skewness, but ensure finite\n",
    "assert math.isfinite(mean_absolute_percentage_error), 'MAPE not finite'\n",
    "print('Basic integrity checks passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521b683",
   "metadata": {},
   "source": [
    "## 12. Automate Rerun with a make-like Script Cell\n",
    "Provide a driver utility to recompute coefficients and emit a standalone function template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2c121c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated coefficients (sanity check):\n",
      "[-679.0882643668813, 864.829109159972, -873.871846814867, 3.487829177620142, 943.5125679600484, -193.64062868253626]\n",
      "\n",
      "Function template snippet:\n",
      "\n",
      "def estimateBuckets(n: int, k: int) -> float:\n",
      "    from math import log as _log, exp as _exp\n",
      "    a,b,c,d,e,f = (-679.0882643668813, 864.829109159972, -873.871846814867, 3.487829177620142, 943.5125679600484, -193.64062868253626)\n",
      "    if n<=0 or k<=0: raise ValueError('n and k must be positive')\n",
      "    ln_n=_log(n); ln_k=_log(k)\n",
      "    val = (a + b*ln_n + c*ln_k + d*ln_n*ln_k + e*(k/n) + f*(n/k))\n",
      "    return _exp(val)\n"
     ]
    }
   ],
   "source": [
    "# Section 12: Driver utility\n",
    "\n",
    "def regenerate_model_and_function(path_csv: str = 'df_oddEven.csv') -> dict:\n",
    "    dataset_rows = []\n",
    "    with Path(path_csv).open() as handle:\n",
    "        dataset_reader = csv.DictReader(handle)\n",
    "        for row in dataset_reader:\n",
    "            dataset_rows.append({key: int(value) for key, value in row.items()})\n",
    "    array_n = numpy.array([r['n'] for r in dataset_rows], dtype=float)\n",
    "    array_k = numpy.array([r['k'] for r in dataset_rows], dtype=float)\n",
    "    array_b = numpy.array([r['buckets'] for r in dataset_rows], dtype=float)\n",
    "    ln_n = numpy.log(array_n)\n",
    "    ln_k = numpy.log(array_k)\n",
    "    ln_b = numpy.log(array_b)\n",
    "    matrix_X = numpy.column_stack([\n",
    "        numpy.ones_like(array_n), ln_n, ln_k, ln_n * ln_k, array_k / array_n, array_n / array_k\n",
    "    ])\n",
    "    coefficients_new, *_ = numpy.linalg.lstsq(matrix_X, ln_b, rcond=None)\n",
    "    template = f\"\"\"def estimateBuckets(n: int, k: int) -> float:\\n    from math import log as _log, exp as _exp\\n    a,b,c,d,e,f = {tuple(float(c) for c in coefficients_new)}\\n    if n<=0 or k<=0: raise ValueError('n and k must be positive')\\n    ln_n=_log(n); ln_k=_log(k)\\n    val = (a + b*ln_n + c*ln_k + d*ln_n*ln_k + e*(k/n) + f*(n/k))\\n    return _exp(val)\\n\"\"\".strip()\n",
    "    return {\n",
    "        'coefficients': [float(c) for c in coefficients_new],\n",
    "        'function_template': template,\n",
    "        'rows': len(dataset_rows),\n",
    "    }\n",
    "\n",
    "result_regen = regenerate_model_and_function()\n",
    "print('Regenerated coefficients (sanity check):')\n",
    "print(result_regen['coefficients'])\n",
    "print('\\nFunction template snippet:\\n')\n",
    "print(result_regen['function_template'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vanalysis (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
